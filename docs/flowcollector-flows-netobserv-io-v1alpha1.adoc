// Automatically generated by 'openshift-apidocs-gen'. Do not edit.
:_content-type: ASSEMBLY
[id="flowcollector-flows-netobserv-io-v1alpha1"]
= FlowCollector [flows.netobserv.io/v1alpha1]
:toc: macro
:toc-title:

toc::[]


Description::
+
--
FlowCollector is the Schema for the flowcollectors API, which pilots and configures netflow collection.
--

Type::
  `object`



== Specification

[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `apiVersion`
| `string`
| APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources

| `kind`
| `string`
| Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds

| `metadata`
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.ObjectMeta[`ObjectMeta`]
| Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata

| `spec`
| `object`
| FlowCollectorSpec defines the desired state of FlowCollector

| `status`
| `object`
| FlowCollectorStatus defines the observed state of FlowCollector

|===
=== .spec
Description::
+
--
FlowCollectorSpec defines the desired state of FlowCollector
--

Type::
  `object`

Required::
  - `agent`
  - `deploymentModel`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `agent`
| `object`
| agent for flows extraction.

| `consolePlugin`
| `object`
| consolePlugin defines the settings related to the OpenShift Console plugin, when available.

| `deploymentModel`
| `string`
| deploymentModel defines the desired type of deployment for flow processing. Possible values are "DIRECT" (default) to make the flow processor listening directly from the agents, or "KAFKA" to make flows sent to a Kafka pipeline before consumption by the processor. Kafka can provide better scalability, resiliency and high availability (for more details, see https://www.redhat.com/en/topics/integration/what-is-apache-kafka).

| `exporters`
| `array`
| exporters defines additional optional exporters for custom consumption or storage. This is an experimental feature. Currently, only KAFKA exporter is available.

| `exporters[]`
| `object`
| FlowCollectorExporter defines an additional exporter to send enriched flows to

| `kafka`
| `object`
| kafka configuration, allowing to use Kafka as a broker as part of the flow collection pipeline. Available when the "spec.deploymentModel" is "KAFKA".

| `loki`
| `object`
| loki, the flow store, client settings.

| `namespace`
| `string`
| namespace where NetObserv pods are deployed. If empty, the namespace of the operator is going to be used.

| `processor`
| `object`
| processor defines the settings of the component that receives the flows from the agent, enriches them, and forwards them to the Loki persistence layer.

|===
=== .spec.agent
Description::
+
--
agent for flows extraction.
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `ebpf`
| `object`
| ebpf describes the settings related to the eBPF-based flow reporter when the "agent.type" property is set to "EBPF".

| `ipfix`
| `object`
| ipfix describes the settings related to the IPFIX-based flow reporter when the "agent.type" property is set to "IPFIX".

| `type`
| `string`
| type selects the flows tracing agent. Possible values are "EBPF" (default) to use NetObserv eBPF agent, "IPFIX" to use the legacy IPFIX collector. "EBPF" is recommended in most cases as it offers better performances and should work regardless of the CNI installed on the cluster. "IPFIX" works with OVN-Kubernetes CNI (other CNIs could work if they support exporting IPFIX, but they would require manual configuration).

|===
=== .spec.agent.ebpf
Description::
+
--
ebpf describes the settings related to the eBPF-based flow reporter when the "agent.type" property is set to "EBPF".
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `cacheActiveTimeout`
| `string`
| cacheActiveTimeout is the max period during which the reporter will aggregate flows before sending

| `cacheMaxFlows`
| `integer`
| cacheMaxFlows is the max number of flows in an aggregate; when reached, the reporter sends the flows

| `debug`
| `object`
| Debug allows setting some aspects of the internal configuration of the eBPF agent. This section is aimed exclusively for debugging and fine-grained performance optimizations (e.g. GOGC, GOMAXPROCS env vars). Users setting its values do it at their own risk.

| `excludeInterfaces`
| `array (string)`
| excludeInterfaces contains the interface names that will be excluded from flow tracing. If an entry is enclosed by slashes (e.g. `/br-/`), it will match as regular expression, otherwise it will be matched as a case-sensitive string.

| `imagePullPolicy`
| `string`
| imagePullPolicy is the Kubernetes pull policy for the image defined above

| `interfaces`
| `array (string)`
| interfaces contains the interface names from where flows will be collected. If empty, the agent will fetch all the interfaces in the system, excepting the ones listed in ExcludeInterfaces. If an entry is enclosed by slashes (e.g. `/br-/`), it will match as regular expression, otherwise it will be matched as a case-sensitive string.

| `kafkaBatchSize`
| `integer`
| kafkaBatchSize limits the maximum size of a request in bytes before being sent to a partition. Ignored when not using Kafka. Default: 10MB.

| `logLevel`
| `string`
| logLevel defines the log level for the NetObserv eBPF Agent

| `privileged`
| `boolean`
| privileged mode for the eBPF Agent container. In general this setting can be ignored or set to false: in that case, the operator will set granular capabilities (BPF, PERFMON, NET_ADMIN, SYS_RESOURCE) to the container, to enable its correct operation. If for some reason these capabilities cannot be set (e.g. old kernel version not knowing CAP_BPF) then you can turn on this mode for more global privileges.

| `resources`
| `object`
| resources are the compute resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `sampling`
| `integer`
| sampling rate of the flow reporter. 100 means one flow on 100 is sent. 0 or 1 means all flows are sampled.

|===
=== .spec.agent.ebpf.debug
Description::
+
--
Debug allows setting some aspects of the internal configuration of the eBPF agent. This section is aimed exclusively for debugging and fine-grained performance optimizations (e.g. GOGC, GOMAXPROCS env vars). Users setting its values do it at their own risk.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `env`
| `object (string)`
| env allows passing custom environment variables to the NetObserv Agent. Useful for passing some very concrete performance-tuning options (e.g. GOGC, GOMAXPROCS) that shouldn't be publicly exposed as part of the FlowCollector descriptor, as they are only useful in edge debug/support scenarios.

|===
=== .spec.agent.ebpf.resources
Description::
+
--
resources are the compute resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `limits`
| `integer-or-string`
| Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `requests`
| `integer-or-string`
| Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
=== .spec.agent.ipfix
Description::
+
--
ipfix describes the settings related to the IPFIX-based flow reporter when the "agent.type" property is set to "IPFIX".
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `cacheActiveTimeout`
| `string`
| cacheActiveTimeout is the max period during which the reporter will aggregate flows before sending

| `cacheMaxFlows`
| `integer`
| cacheMaxFlows is the max number of flows in an aggregate; when reached, the reporter sends the flows

| `clusterNetworkOperator`
| `object`
| clusterNetworkOperator defines the settings related to the OpenShift Cluster Network Operator, when available.

| `forceSampleAll`
| `boolean`
| forceSampleAll allows disabling sampling in the IPFIX-based flow reporter. It is not recommended to sample all the traffic with IPFIX, as it may generate cluster instability. If you REALLY want to do that, set this flag to true. Use at your own risk. When it is set to true, the value of "sampling" is ignored.

| `ovnKubernetes`
| `object`
| ovnKubernetes defines the settings of the OVN-Kubernetes CNI, when available. This configuration is used when using OVN's IPFIX exports, without OpenShift. When using OpenShift, refer to the `clusterNetworkOperator` property instead.

| `sampling`
| `integer`
| sampling is the sampling rate on the reporter. 100 means one flow on 100 is sent. To ensure cluster stability, it is not possible to set a value below 2. If you really want to sample every packet, which may impact the cluster stability, refer to "forceSampleAll". Alternatively, you can use the eBPF Agent instead of IPFIX.

|===
=== .spec.agent.ipfix.clusterNetworkOperator
Description::
+
--
clusterNetworkOperator defines the settings related to the OpenShift Cluster Network Operator, when available.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `namespace`
| `string`
| namespace  where the configmap is going to be deployed.

|===
=== .spec.agent.ipfix.ovnKubernetes
Description::
+
--
ovnKubernetes defines the settings of the OVN-Kubernetes CNI, when available. This configuration is used when using OVN's IPFIX exports, without OpenShift. When using OpenShift, refer to the `clusterNetworkOperator` property instead.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `containerName`
| `string`
| containerName defines the name of the container to configure for IPFIX.

| `daemonSetName`
| `string`
| daemonSetName defines the name of the DaemonSet controlling the OVN-Kubernetes pods.

| `namespace`
| `string`
| namespace where OVN-Kubernetes pods are deployed.

|===
=== .spec.consolePlugin
Description::
+
--
consolePlugin defines the settings related to the OpenShift Console plugin, when available.
--

Type::
  `object`

Required::
  - `register`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `autoscaler`
| `object`
| autoscaler spec of a horizontal pod autoscaler to set up for the plugin Deployment.

| `imagePullPolicy`
| `string`
| imagePullPolicy is the Kubernetes pull policy for the image defined above

| `logLevel`
| `string`
| logLevel for the console plugin backend

| `port`
| `integer`
| port is the plugin service port

| `portNaming`
| `object`
| portNaming defines the configuration of the port-to-service name translation

| `quickFilters`
| `array`
| quickFilters configures quick filter presets for the Console plugin

| `quickFilters[]`
| `object`
| QuickFilter defines preset configuration for Console's quick filters

| `register`
| `boolean`
| register allows, when set to true, to automatically register the provided console plugin with the OpenShift Console operator. When set to false, you can still register it manually by editing console.operator.openshift.io/cluster. E.g: oc patch console.operator.openshift.io cluster --type='json' -p '[{"op": "add", "path": "/spec/plugins/-", "value": "netobserv-plugin"}]'

| `replicas`
| `integer`
| replicas defines the number of replicas (pods) to start.

| `resources`
| `object`
| resources, in terms of compute resources, required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
=== .spec.consolePlugin.autoscaler
Description::
+
--
autoscaler spec of a horizontal pod autoscaler to set up for the plugin Deployment.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `maxReplicas`
| `integer`
| maxReplicas is the upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than MinReplicas.

| `metrics`
| `array`
| metrics used by the pod autoscaler

| `metrics[]`
| `object`
| MetricSpec specifies how to scale based on a single metric (only `type` and one other matching field should be set at once).

| `minReplicas`
| `integer`
| minReplicas is the lower limit for the number of replicas to which the autoscaler can scale down.  It defaults to 1 pod.  minReplicas is allowed to be 0 if the alpha feature gate HPAScaleToZero is enabled and at least one Object or External metric is configured.  Scaling is active as long as at least one metric value is available.

| `status`
| `string`
| Status describe the desired status regarding deploying an horizontal pod autoscaler DISABLED will not deploy an horizontal pod autoscaler ENABLED will deploy an horizontal pod autoscaler

|===
=== .spec.consolePlugin.autoscaler.metrics
Description::
+
--
metrics used by the pod autoscaler
--

Type::
  `array`




=== .spec.consolePlugin.autoscaler.metrics[]
Description::
+
--
MetricSpec specifies how to scale based on a single metric (only `type` and one other matching field should be set at once).
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `containerResource`
| `object`
| containerResource refers to a resource metric (such as those specified in requests and limits) known to Kubernetes describing a single container in each pod of the current scale target (e.g. CPU or memory). Such metrics are built in to Kubernetes, and have special scaling options on top of those available to normal per-pod metrics using the "pods" source. This is an alpha feature and can be enabled by the HPAContainerMetrics feature flag.

| `external`
| `object`
| external refers to a global metric that is not associated with any Kubernetes object. It allows autoscaling based on information coming from components running outside of cluster (for example length of queue in cloud messaging service, or QPS from loadbalancer running outside of cluster).

| `object`
| `object`
| object refers to a metric describing a single kubernetes object (for example, hits-per-second on an Ingress object).

| `pods`
| `object`
| pods refers to a metric describing each pod in the current scale target (for example, transactions-processed-per-second).  The values will be averaged together before being compared to the target value.

| `resource`
| `object`
| resource refers to a resource metric (such as those specified in requests and limits) known to Kubernetes describing each pod in the current scale target (e.g. CPU or memory). Such metrics are built in to Kubernetes, and have special scaling options on top of those available to normal per-pod metrics using the "pods" source.

| `type`
| `string`
| type is the type of metric source.  It should be one of "ContainerResource", "External", "Object", "Pods" or "Resource", each mapping to a matching field in the object. Note: "ContainerResource" type is available on when the feature-gate HPAContainerMetrics is enabled

|===
=== .spec.consolePlugin.autoscaler.metrics[].containerResource
Description::
+
--
containerResource refers to a resource metric (such as those specified in requests and limits) known to Kubernetes describing a single container in each pod of the current scale target (e.g. CPU or memory). Such metrics are built in to Kubernetes, and have special scaling options on top of those available to normal per-pod metrics using the "pods" source. This is an alpha feature and can be enabled by the HPAContainerMetrics feature flag.
--

Type::
  `object`

Required::
  - `container`
  - `name`
  - `target`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `container`
| `string`
| container is the name of the container in the pods of the scaling target

| `name`
| `string`
| name is the name of the resource in question.

| `target`
| `object`
| target specifies the target value for the given metric

|===
=== .spec.consolePlugin.autoscaler.metrics[].containerResource.target
Description::
+
--
target specifies the target value for the given metric
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `averageUtilization`
| `integer`
| averageUtilization is the target value of the average of the resource metric across all relevant pods, represented as a percentage of the requested value of the resource for the pods. Currently only valid for Resource metric source type

| `averageValue`
| `integer-or-string`
| averageValue is the target value of the average of the metric across all relevant pods (as a quantity)

| `type`
| `string`
| type represents whether the metric type is Utilization, Value, or AverageValue

| `value`
| `integer-or-string`
| value is the target value of the metric (as a quantity).

|===
=== .spec.consolePlugin.autoscaler.metrics[].external
Description::
+
--
external refers to a global metric that is not associated with any Kubernetes object. It allows autoscaling based on information coming from components running outside of cluster (for example length of queue in cloud messaging service, or QPS from loadbalancer running outside of cluster).
--

Type::
  `object`

Required::
  - `metric`
  - `target`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `metric`
| `object`
| metric identifies the target metric by name and selector

| `target`
| `object`
| target specifies the target value for the given metric

|===
=== .spec.consolePlugin.autoscaler.metrics[].external.metric
Description::
+
--
metric identifies the target metric by name and selector
--

Type::
  `object`

Required::
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| name is the name of the given metric

| `selector`
| `object`
| selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.

|===
=== .spec.consolePlugin.autoscaler.metrics[].external.metric.selector
Description::
+
--
selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `matchExpressions`
| `array`
| matchExpressions is a list of label selector requirements. The requirements are ANDed.

| `matchExpressions[]`
| `object`
| A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.

| `matchLabels`
| `object (string)`
| matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.

|===
=== .spec.consolePlugin.autoscaler.metrics[].external.metric.selector.matchExpressions
Description::
+
--
matchExpressions is a list of label selector requirements. The requirements are ANDed.
--

Type::
  `array`




=== .spec.consolePlugin.autoscaler.metrics[].external.metric.selector.matchExpressions[]
Description::
+
--
A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
--

Type::
  `object`

Required::
  - `key`
  - `operator`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `key`
| `string`
| key is the label key that the selector applies to.

| `operator`
| `string`
| operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.

| `values`
| `array (string)`
| values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.

|===
=== .spec.consolePlugin.autoscaler.metrics[].external.target
Description::
+
--
target specifies the target value for the given metric
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `averageUtilization`
| `integer`
| averageUtilization is the target value of the average of the resource metric across all relevant pods, represented as a percentage of the requested value of the resource for the pods. Currently only valid for Resource metric source type

| `averageValue`
| `integer-or-string`
| averageValue is the target value of the average of the metric across all relevant pods (as a quantity)

| `type`
| `string`
| type represents whether the metric type is Utilization, Value, or AverageValue

| `value`
| `integer-or-string`
| value is the target value of the metric (as a quantity).

|===
=== .spec.consolePlugin.autoscaler.metrics[].object
Description::
+
--
object refers to a metric describing a single kubernetes object (for example, hits-per-second on an Ingress object).
--

Type::
  `object`

Required::
  - `describedObject`
  - `metric`
  - `target`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `describedObject`
| `object`
| describedObject specifies the descriptions of a object,such as kind,name apiVersion

| `metric`
| `object`
| metric identifies the target metric by name and selector

| `target`
| `object`
| target specifies the target value for the given metric

|===
=== .spec.consolePlugin.autoscaler.metrics[].object.describedObject
Description::
+
--
describedObject specifies the descriptions of a object,such as kind,name apiVersion
--

Type::
  `object`

Required::
  - `kind`
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `apiVersion`
| `string`
| API version of the referent

| `kind`
| `string`
| Kind of the referent; More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds"

| `name`
| `string`
| Name of the referent; More info: http://kubernetes.io/docs/user-guide/identifiers#names

|===
=== .spec.consolePlugin.autoscaler.metrics[].object.metric
Description::
+
--
metric identifies the target metric by name and selector
--

Type::
  `object`

Required::
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| name is the name of the given metric

| `selector`
| `object`
| selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.

|===
=== .spec.consolePlugin.autoscaler.metrics[].object.metric.selector
Description::
+
--
selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `matchExpressions`
| `array`
| matchExpressions is a list of label selector requirements. The requirements are ANDed.

| `matchExpressions[]`
| `object`
| A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.

| `matchLabels`
| `object (string)`
| matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.

|===
=== .spec.consolePlugin.autoscaler.metrics[].object.metric.selector.matchExpressions
Description::
+
--
matchExpressions is a list of label selector requirements. The requirements are ANDed.
--

Type::
  `array`




=== .spec.consolePlugin.autoscaler.metrics[].object.metric.selector.matchExpressions[]
Description::
+
--
A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
--

Type::
  `object`

Required::
  - `key`
  - `operator`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `key`
| `string`
| key is the label key that the selector applies to.

| `operator`
| `string`
| operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.

| `values`
| `array (string)`
| values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.

|===
=== .spec.consolePlugin.autoscaler.metrics[].object.target
Description::
+
--
target specifies the target value for the given metric
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `averageUtilization`
| `integer`
| averageUtilization is the target value of the average of the resource metric across all relevant pods, represented as a percentage of the requested value of the resource for the pods. Currently only valid for Resource metric source type

| `averageValue`
| `integer-or-string`
| averageValue is the target value of the average of the metric across all relevant pods (as a quantity)

| `type`
| `string`
| type represents whether the metric type is Utilization, Value, or AverageValue

| `value`
| `integer-or-string`
| value is the target value of the metric (as a quantity).

|===
=== .spec.consolePlugin.autoscaler.metrics[].pods
Description::
+
--
pods refers to a metric describing each pod in the current scale target (for example, transactions-processed-per-second).  The values will be averaged together before being compared to the target value.
--

Type::
  `object`

Required::
  - `metric`
  - `target`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `metric`
| `object`
| metric identifies the target metric by name and selector

| `target`
| `object`
| target specifies the target value for the given metric

|===
=== .spec.consolePlugin.autoscaler.metrics[].pods.metric
Description::
+
--
metric identifies the target metric by name and selector
--

Type::
  `object`

Required::
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| name is the name of the given metric

| `selector`
| `object`
| selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.

|===
=== .spec.consolePlugin.autoscaler.metrics[].pods.metric.selector
Description::
+
--
selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `matchExpressions`
| `array`
| matchExpressions is a list of label selector requirements. The requirements are ANDed.

| `matchExpressions[]`
| `object`
| A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.

| `matchLabels`
| `object (string)`
| matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.

|===
=== .spec.consolePlugin.autoscaler.metrics[].pods.metric.selector.matchExpressions
Description::
+
--
matchExpressions is a list of label selector requirements. The requirements are ANDed.
--

Type::
  `array`




=== .spec.consolePlugin.autoscaler.metrics[].pods.metric.selector.matchExpressions[]
Description::
+
--
A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
--

Type::
  `object`

Required::
  - `key`
  - `operator`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `key`
| `string`
| key is the label key that the selector applies to.

| `operator`
| `string`
| operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.

| `values`
| `array (string)`
| values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.

|===
=== .spec.consolePlugin.autoscaler.metrics[].pods.target
Description::
+
--
target specifies the target value for the given metric
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `averageUtilization`
| `integer`
| averageUtilization is the target value of the average of the resource metric across all relevant pods, represented as a percentage of the requested value of the resource for the pods. Currently only valid for Resource metric source type

| `averageValue`
| `integer-or-string`
| averageValue is the target value of the average of the metric across all relevant pods (as a quantity)

| `type`
| `string`
| type represents whether the metric type is Utilization, Value, or AverageValue

| `value`
| `integer-or-string`
| value is the target value of the metric (as a quantity).

|===
=== .spec.consolePlugin.autoscaler.metrics[].resource
Description::
+
--
resource refers to a resource metric (such as those specified in requests and limits) known to Kubernetes describing each pod in the current scale target (e.g. CPU or memory). Such metrics are built in to Kubernetes, and have special scaling options on top of those available to normal per-pod metrics using the "pods" source.
--

Type::
  `object`

Required::
  - `name`
  - `target`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| name is the name of the resource in question.

| `target`
| `object`
| target specifies the target value for the given metric

|===
=== .spec.consolePlugin.autoscaler.metrics[].resource.target
Description::
+
--
target specifies the target value for the given metric
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `averageUtilization`
| `integer`
| averageUtilization is the target value of the average of the resource metric across all relevant pods, represented as a percentage of the requested value of the resource for the pods. Currently only valid for Resource metric source type

| `averageValue`
| `integer-or-string`
| averageValue is the target value of the average of the metric across all relevant pods (as a quantity)

| `type`
| `string`
| type represents whether the metric type is Utilization, Value, or AverageValue

| `value`
| `integer-or-string`
| value is the target value of the metric (as a quantity).

|===
=== .spec.consolePlugin.portNaming
Description::
+
--
portNaming defines the configuration of the port-to-service name translation
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `enable`
| `boolean`
| enable the console plugin port-to-service name translation

| `portNames`
| `object (string)`
| portNames defines additional port names to use in the console E.g. portNames: {"3100": "loki"}

|===
=== .spec.consolePlugin.quickFilters
Description::
+
--
quickFilters configures quick filter presets for the Console plugin
--

Type::
  `array`




=== .spec.consolePlugin.quickFilters[]
Description::
+
--
QuickFilter defines preset configuration for Console's quick filters
--

Type::
  `object`

Required::
  - `filter`
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `default`
| `boolean`
| default defines whether this filter should be active by default or not

| `filter`
| `object (string)`
| filter is a set of keys and values to be set when this filter is selected. Each key can relate to a list of values using a coma-separated string E.g. filter: {"src_namespace": "namespace1,namespace2"}

| `name`
| `string`
| name of the filter, that will be displayed in Console

|===
=== .spec.consolePlugin.resources
Description::
+
--
resources, in terms of compute resources, required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `limits`
| `integer-or-string`
| Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `requests`
| `integer-or-string`
| Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
=== .spec.exporters
Description::
+
--
exporters defines additional optional exporters for custom consumption or storage. This is an experimental feature. Currently, only KAFKA exporter is available.
--

Type::
  `array`




=== .spec.exporters[]
Description::
+
--
FlowCollectorExporter defines an additional exporter to send enriched flows to
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `kafka`
| `object`
| kafka describes the kafka configuration (address, topic...) to send enriched flows to.

| `type`
| `string`
| type selects the type of exporte. Only "KAFKA" is available at the moment.

|===
=== .spec.exporters[].kafka
Description::
+
--
kafka describes the kafka configuration (address, topic...) to send enriched flows to.
--

Type::
  `object`

Required::
  - `address`
  - `topic`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `address`
| `string`
| address of the Kafka server

| `tls`
| `object`
| tls client configuration. When using TLS, make sure the address matches the Kafka port used for TLS, generally 9093. Note that, when eBPF agents are used, Kafka certificate needs to be copied in the agent namespace (by default it's netobserv-privileged).

| `topic`
| `string`
| kafka topic to use. It must exist, NetObserv will not create it.

|===
=== .spec.exporters[].kafka.tls
Description::
+
--
tls client configuration. When using TLS, make sure the address matches the Kafka port used for TLS, generally 9093. Note that, when eBPF agents are used, Kafka certificate needs to be copied in the agent namespace (by default it's netobserv-privileged).
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `caCert`
| `object`
| caCert defines the reference of the certificate for the Certificate Authority

| `enable`
| `boolean`
| enable TLS

| `insecureSkipVerify`
| `boolean`
| insecureSkipVerify allows skipping client-side verification of the server certificate If set to true, CACert field will be ignored

| `userCert`
| `object`
| userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)

|===
=== .spec.exporters[].kafka.tls.caCert
Description::
+
--
caCert defines the reference of the certificate for the Certificate Authority
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the ConfigMap / Secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the ConfigMap / Secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the ConfigMap or Secret containing certificates

| `type`
| `string`
| type for the certificate reference: configmap or secret

|===
=== .spec.exporters[].kafka.tls.userCert
Description::
+
--
userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the ConfigMap / Secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the ConfigMap / Secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the ConfigMap or Secret containing certificates

| `type`
| `string`
| type for the certificate reference: configmap or secret

|===
=== .spec.kafka
Description::
+
--
kafka configuration, allowing to use Kafka as a broker as part of the flow collection pipeline. Available when the "spec.deploymentModel" is "KAFKA".
--

Type::
  `object`

Required::
  - `address`
  - `topic`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `address`
| `string`
| address of the Kafka server

| `tls`
| `object`
| tls client configuration. When using TLS, make sure the address matches the Kafka port used for TLS, generally 9093. Note that, when eBPF agents are used, Kafka certificate needs to be copied in the agent namespace (by default it's netobserv-privileged).

| `topic`
| `string`
| kafka topic to use. It must exist, NetObserv will not create it.

|===
=== .spec.kafka.tls
Description::
+
--
tls client configuration. When using TLS, make sure the address matches the Kafka port used for TLS, generally 9093. Note that, when eBPF agents are used, Kafka certificate needs to be copied in the agent namespace (by default it's netobserv-privileged).
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `caCert`
| `object`
| caCert defines the reference of the certificate for the Certificate Authority

| `enable`
| `boolean`
| enable TLS

| `insecureSkipVerify`
| `boolean`
| insecureSkipVerify allows skipping client-side verification of the server certificate If set to true, CACert field will be ignored

| `userCert`
| `object`
| userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)

|===
=== .spec.kafka.tls.caCert
Description::
+
--
caCert defines the reference of the certificate for the Certificate Authority
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the ConfigMap / Secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the ConfigMap / Secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the ConfigMap or Secret containing certificates

| `type`
| `string`
| type for the certificate reference: configmap or secret

|===
=== .spec.kafka.tls.userCert
Description::
+
--
userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the ConfigMap / Secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the ConfigMap / Secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the ConfigMap or Secret containing certificates

| `type`
| `string`
| type for the certificate reference: configmap or secret

|===
=== .spec.loki
Description::
+
--
loki, the flow store, client settings.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `authToken`
| `string`
| AuthToken describe the way to get a token to authenticate to Loki DISABLED will not send any token with the request HOST will use the local pod service account to authenticate to Loki FORWARD will forward user token, in this mode, pod that are not receiving user request like the processor will use the local pod service account. Similar to HOST mode.

| `batchSize`
| `integer`
| batchSize is max batch size (in bytes) of logs to accumulate before sending

| `batchWait`
| `string`
| batchWait is max time to wait before sending a batch

| `maxBackoff`
| `string`
| maxBackoff is the maximum backoff time for client connection between retries

| `maxRetries`
| `integer`
| maxRetries is the maximum number of retries for client connections

| `minBackoff`
| `string`
| minBackoff is the initial backoff time for client connection between retries

| `querierUrl`
| `string`
| querierURL specifies the address of the Loki querier service, in case it is different from the Loki ingester URL. If empty, the URL value will be used (assuming that the Loki ingester and querier are in the same server).

| `staticLabels`
| `object (string)`
| staticLabels is a map of common labels to set on each flow

| `statusUrl`
| `string`
| statusURL specifies the address of the Loki /ready /metrics /config endpoints, in case it is different from the Loki querier URL. If empty, the QuerierURL value will be used. This is useful to show error messages and some context in the frontend

| `tenantID`
| `string`
| tenantID is the Loki X-Scope-OrgID that identifies the tenant for each request. it will be ignored if instanceSpec is specified

| `timeout`
| `string`
| timeout is the maximum time connection / request limit A Timeout of zero means no timeout.

| `tls`
| `object`
| tls client configuration.

| `url`
| `string`
| url is the address of an existing Loki service to push the flows to.

|===
=== .spec.loki.tls
Description::
+
--
tls client configuration.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `caCert`
| `object`
| caCert defines the reference of the certificate for the Certificate Authority

| `enable`
| `boolean`
| enable TLS

| `insecureSkipVerify`
| `boolean`
| insecureSkipVerify allows skipping client-side verification of the server certificate If set to true, CACert field will be ignored

| `userCert`
| `object`
| userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)

|===
=== .spec.loki.tls.caCert
Description::
+
--
caCert defines the reference of the certificate for the Certificate Authority
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the ConfigMap / Secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the ConfigMap / Secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the ConfigMap or Secret containing certificates

| `type`
| `string`
| type for the certificate reference: configmap or secret

|===
=== .spec.loki.tls.userCert
Description::
+
--
userCert defines the user certificate reference, used for mTLS (you can ignore it when using regular, one-way TLS)
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the ConfigMap / Secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the ConfigMap / Secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the ConfigMap or Secret containing certificates

| `type`
| `string`
| type for the certificate reference: configmap or secret

|===
=== .spec.processor
Description::
+
--
processor defines the settings of the component that receives the flows from the agent, enriches them, and forwards them to the Loki persistence layer.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `debug`
| `object`
| Debug allows setting some aspects of the internal configuration of the flow processor. This section is aimed exclusively for debugging and fine-grained performance optimizations (e.g. GOGC, GOMAXPROCS env vars). Users setting its values do it at their own risk.

| `dropUnusedFields`
| `boolean`
| dropUnusedFields allows, when set to true, to drop fields that are known to be unused by OVS, in order to save storage space.

| `enableKubeProbes`
| `boolean`
| enableKubeProbes is a flag to enable or disable Kubernetes liveness/readiness probes

| `healthPort`
| `integer`
| healthPort is a collector HTTP port in the Pod that exposes the health check API

| `imagePullPolicy`
| `string`
| imagePullPolicy is the Kubernetes pull policy for the image defined above

| `kafkaConsumerAutoscaler`
| `object`
| kafkaConsumerAutoscaler spec of a horizontal pod autoscaler to set up for flowlogs-pipeline-transformer, which consumes Kafka messages. This setting is ignored when Kafka is disabled.

| `kafkaConsumerBatchSize`
| `integer`
| kafkaConsumerBatchSize indicates to the broker the maximum batch size, in bytes, that the consumer will accept. Ignored when not using Kafka. Default: 10MB.

| `kafkaConsumerQueueCapacity`
| `integer`
| kafkaConsumerQueueCapacity defines the capacity of the internal message queue used in the Kafka consumer client. Ignored when not using Kafka.

| `kafkaConsumerReplicas`
| `integer`
| kafkaConsumerReplicas defines the number of replicas (pods) to start for flowlogs-pipeline-transformer, which consumes Kafka messages. This setting is ignored when Kafka is disabled.

| `logLevel`
| `string`
| logLevel of the collector runtime

| `metrics`
| `object`
| Metrics define the processor configuration regarding metrics

| `port`
| `integer`
| port of the flow collector (host port) By conventions, some value are not authorized port must not be below 1024 and must not equal this values: 4789,6081,500, and 4500

| `profilePort`
| `integer`
| profilePort allows setting up a Go pprof profiler listening to this port

| `resources`
| `object`
| resources are the compute resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
=== .spec.processor.debug
Description::
+
--
Debug allows setting some aspects of the internal configuration of the flow processor. This section is aimed exclusively for debugging and fine-grained performance optimizations (e.g. GOGC, GOMAXPROCS env vars). Users setting its values do it at their own risk.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `env`
| `object (string)`
| env allows passing custom environment variables to the NetObserv Agent. Useful for passing some very concrete performance-tuning options (e.g. GOGC, GOMAXPROCS) that shouldn't be publicly exposed as part of the FlowCollector descriptor, as they are only useful in edge debug/support scenarios.

|===
=== .spec.processor.kafkaConsumerAutoscaler
Description::
+
--
kafkaConsumerAutoscaler spec of a horizontal pod autoscaler to set up for flowlogs-pipeline-transformer, which consumes Kafka messages. This setting is ignored when Kafka is disabled.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `maxReplicas`
| `integer`
| maxReplicas is the upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than MinReplicas.

| `metrics`
| `array`
| metrics used by the pod autoscaler

| `metrics[]`
| `object`
| MetricSpec specifies how to scale based on a single metric (only `type` and one other matching field should be set at once).

| `minReplicas`
| `integer`
| minReplicas is the lower limit for the number of replicas to which the autoscaler can scale down.  It defaults to 1 pod.  minReplicas is allowed to be 0 if the alpha feature gate HPAScaleToZero is enabled and at least one Object or External metric is configured.  Scaling is active as long as at least one metric value is available.

| `status`
| `string`
| Status describe the desired status regarding deploying an horizontal pod autoscaler DISABLED will not deploy an horizontal pod autoscaler ENABLED will deploy an horizontal pod autoscaler

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics
Description::
+
--
metrics used by the pod autoscaler
--

Type::
  `array`




=== .spec.processor.kafkaConsumerAutoscaler.metrics[]
Description::
+
--
MetricSpec specifies how to scale based on a single metric (only `type` and one other matching field should be set at once).
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `containerResource`
| `object`
| containerResource refers to a resource metric (such as those specified in requests and limits) known to Kubernetes describing a single container in each pod of the current scale target (e.g. CPU or memory). Such metrics are built in to Kubernetes, and have special scaling options on top of those available to normal per-pod metrics using the "pods" source. This is an alpha feature and can be enabled by the HPAContainerMetrics feature flag.

| `external`
| `object`
| external refers to a global metric that is not associated with any Kubernetes object. It allows autoscaling based on information coming from components running outside of cluster (for example length of queue in cloud messaging service, or QPS from loadbalancer running outside of cluster).

| `object`
| `object`
| object refers to a metric describing a single kubernetes object (for example, hits-per-second on an Ingress object).

| `pods`
| `object`
| pods refers to a metric describing each pod in the current scale target (for example, transactions-processed-per-second).  The values will be averaged together before being compared to the target value.

| `resource`
| `object`
| resource refers to a resource metric (such as those specified in requests and limits) known to Kubernetes describing each pod in the current scale target (e.g. CPU or memory). Such metrics are built in to Kubernetes, and have special scaling options on top of those available to normal per-pod metrics using the "pods" source.

| `type`
| `string`
| type is the type of metric source.  It should be one of "ContainerResource", "External", "Object", "Pods" or "Resource", each mapping to a matching field in the object. Note: "ContainerResource" type is available on when the feature-gate HPAContainerMetrics is enabled

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].containerResource
Description::
+
--
containerResource refers to a resource metric (such as those specified in requests and limits) known to Kubernetes describing a single container in each pod of the current scale target (e.g. CPU or memory). Such metrics are built in to Kubernetes, and have special scaling options on top of those available to normal per-pod metrics using the "pods" source. This is an alpha feature and can be enabled by the HPAContainerMetrics feature flag.
--

Type::
  `object`

Required::
  - `container`
  - `name`
  - `target`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `container`
| `string`
| container is the name of the container in the pods of the scaling target

| `name`
| `string`
| name is the name of the resource in question.

| `target`
| `object`
| target specifies the target value for the given metric

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].containerResource.target
Description::
+
--
target specifies the target value for the given metric
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `averageUtilization`
| `integer`
| averageUtilization is the target value of the average of the resource metric across all relevant pods, represented as a percentage of the requested value of the resource for the pods. Currently only valid for Resource metric source type

| `averageValue`
| `integer-or-string`
| averageValue is the target value of the average of the metric across all relevant pods (as a quantity)

| `type`
| `string`
| type represents whether the metric type is Utilization, Value, or AverageValue

| `value`
| `integer-or-string`
| value is the target value of the metric (as a quantity).

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].external
Description::
+
--
external refers to a global metric that is not associated with any Kubernetes object. It allows autoscaling based on information coming from components running outside of cluster (for example length of queue in cloud messaging service, or QPS from loadbalancer running outside of cluster).
--

Type::
  `object`

Required::
  - `metric`
  - `target`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `metric`
| `object`
| metric identifies the target metric by name and selector

| `target`
| `object`
| target specifies the target value for the given metric

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].external.metric
Description::
+
--
metric identifies the target metric by name and selector
--

Type::
  `object`

Required::
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| name is the name of the given metric

| `selector`
| `object`
| selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].external.metric.selector
Description::
+
--
selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `matchExpressions`
| `array`
| matchExpressions is a list of label selector requirements. The requirements are ANDed.

| `matchExpressions[]`
| `object`
| A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.

| `matchLabels`
| `object (string)`
| matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].external.metric.selector.matchExpressions
Description::
+
--
matchExpressions is a list of label selector requirements. The requirements are ANDed.
--

Type::
  `array`




=== .spec.processor.kafkaConsumerAutoscaler.metrics[].external.metric.selector.matchExpressions[]
Description::
+
--
A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
--

Type::
  `object`

Required::
  - `key`
  - `operator`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `key`
| `string`
| key is the label key that the selector applies to.

| `operator`
| `string`
| operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.

| `values`
| `array (string)`
| values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].external.target
Description::
+
--
target specifies the target value for the given metric
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `averageUtilization`
| `integer`
| averageUtilization is the target value of the average of the resource metric across all relevant pods, represented as a percentage of the requested value of the resource for the pods. Currently only valid for Resource metric source type

| `averageValue`
| `integer-or-string`
| averageValue is the target value of the average of the metric across all relevant pods (as a quantity)

| `type`
| `string`
| type represents whether the metric type is Utilization, Value, or AverageValue

| `value`
| `integer-or-string`
| value is the target value of the metric (as a quantity).

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].object
Description::
+
--
object refers to a metric describing a single kubernetes object (for example, hits-per-second on an Ingress object).
--

Type::
  `object`

Required::
  - `describedObject`
  - `metric`
  - `target`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `describedObject`
| `object`
| describedObject specifies the descriptions of a object,such as kind,name apiVersion

| `metric`
| `object`
| metric identifies the target metric by name and selector

| `target`
| `object`
| target specifies the target value for the given metric

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].object.describedObject
Description::
+
--
describedObject specifies the descriptions of a object,such as kind,name apiVersion
--

Type::
  `object`

Required::
  - `kind`
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `apiVersion`
| `string`
| API version of the referent

| `kind`
| `string`
| Kind of the referent; More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds"

| `name`
| `string`
| Name of the referent; More info: http://kubernetes.io/docs/user-guide/identifiers#names

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].object.metric
Description::
+
--
metric identifies the target metric by name and selector
--

Type::
  `object`

Required::
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| name is the name of the given metric

| `selector`
| `object`
| selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].object.metric.selector
Description::
+
--
selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `matchExpressions`
| `array`
| matchExpressions is a list of label selector requirements. The requirements are ANDed.

| `matchExpressions[]`
| `object`
| A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.

| `matchLabels`
| `object (string)`
| matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].object.metric.selector.matchExpressions
Description::
+
--
matchExpressions is a list of label selector requirements. The requirements are ANDed.
--

Type::
  `array`




=== .spec.processor.kafkaConsumerAutoscaler.metrics[].object.metric.selector.matchExpressions[]
Description::
+
--
A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
--

Type::
  `object`

Required::
  - `key`
  - `operator`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `key`
| `string`
| key is the label key that the selector applies to.

| `operator`
| `string`
| operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.

| `values`
| `array (string)`
| values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].object.target
Description::
+
--
target specifies the target value for the given metric
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `averageUtilization`
| `integer`
| averageUtilization is the target value of the average of the resource metric across all relevant pods, represented as a percentage of the requested value of the resource for the pods. Currently only valid for Resource metric source type

| `averageValue`
| `integer-or-string`
| averageValue is the target value of the average of the metric across all relevant pods (as a quantity)

| `type`
| `string`
| type represents whether the metric type is Utilization, Value, or AverageValue

| `value`
| `integer-or-string`
| value is the target value of the metric (as a quantity).

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].pods
Description::
+
--
pods refers to a metric describing each pod in the current scale target (for example, transactions-processed-per-second).  The values will be averaged together before being compared to the target value.
--

Type::
  `object`

Required::
  - `metric`
  - `target`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `metric`
| `object`
| metric identifies the target metric by name and selector

| `target`
| `object`
| target specifies the target value for the given metric

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].pods.metric
Description::
+
--
metric identifies the target metric by name and selector
--

Type::
  `object`

Required::
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| name is the name of the given metric

| `selector`
| `object`
| selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].pods.metric.selector
Description::
+
--
selector is the string-encoded form of a standard kubernetes label selector for the given metric When set, it is passed as an additional parameter to the metrics server for more specific metrics scoping. When unset, just the metricName will be used to gather metrics.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `matchExpressions`
| `array`
| matchExpressions is a list of label selector requirements. The requirements are ANDed.

| `matchExpressions[]`
| `object`
| A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.

| `matchLabels`
| `object (string)`
| matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].pods.metric.selector.matchExpressions
Description::
+
--
matchExpressions is a list of label selector requirements. The requirements are ANDed.
--

Type::
  `array`




=== .spec.processor.kafkaConsumerAutoscaler.metrics[].pods.metric.selector.matchExpressions[]
Description::
+
--
A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
--

Type::
  `object`

Required::
  - `key`
  - `operator`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `key`
| `string`
| key is the label key that the selector applies to.

| `operator`
| `string`
| operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.

| `values`
| `array (string)`
| values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].pods.target
Description::
+
--
target specifies the target value for the given metric
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `averageUtilization`
| `integer`
| averageUtilization is the target value of the average of the resource metric across all relevant pods, represented as a percentage of the requested value of the resource for the pods. Currently only valid for Resource metric source type

| `averageValue`
| `integer-or-string`
| averageValue is the target value of the average of the metric across all relevant pods (as a quantity)

| `type`
| `string`
| type represents whether the metric type is Utilization, Value, or AverageValue

| `value`
| `integer-or-string`
| value is the target value of the metric (as a quantity).

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].resource
Description::
+
--
resource refers to a resource metric (such as those specified in requests and limits) known to Kubernetes describing each pod in the current scale target (e.g. CPU or memory). Such metrics are built in to Kubernetes, and have special scaling options on top of those available to normal per-pod metrics using the "pods" source.
--

Type::
  `object`

Required::
  - `name`
  - `target`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| name is the name of the resource in question.

| `target`
| `object`
| target specifies the target value for the given metric

|===
=== .spec.processor.kafkaConsumerAutoscaler.metrics[].resource.target
Description::
+
--
target specifies the target value for the given metric
--

Type::
  `object`

Required::
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `averageUtilization`
| `integer`
| averageUtilization is the target value of the average of the resource metric across all relevant pods, represented as a percentage of the requested value of the resource for the pods. Currently only valid for Resource metric source type

| `averageValue`
| `integer-or-string`
| averageValue is the target value of the average of the metric across all relevant pods (as a quantity)

| `type`
| `string`
| type represents whether the metric type is Utilization, Value, or AverageValue

| `value`
| `integer-or-string`
| value is the target value of the metric (as a quantity).

|===
=== .spec.processor.metrics
Description::
+
--
Metrics define the processor configuration regarding metrics
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `ignoreTags`
| `array (string)`
| ignoreTags is a list of tags to specify which metrics to ignore

| `server`
| `object`
| metricsServer endpoint configuration for Prometheus scraper

|===
=== .spec.processor.metrics.server
Description::
+
--
metricsServer endpoint configuration for Prometheus scraper
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `port`
| `integer`
| the prometheus HTTP port

| `tls`
| `object`
| TLS configuration.

|===
=== .spec.processor.metrics.server.tls
Description::
+
--
TLS configuration.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `provided`
| `object`
| TLS configuration.

| `type`
| `string`
| Select the type of TLS configuration "DISABLED" (default) to not configure TLS for the endpoint, "PROVIDED" to manually provide cert file and a key file, and "AUTO" to use Openshift auto generated certificate using annotations

|===
=== .spec.processor.metrics.server.tls.provided
Description::
+
--
TLS configuration.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `certFile`
| `string`
| certFile defines the path to the certificate file name within the ConfigMap / Secret

| `certKey`
| `string`
| certKey defines the path to the certificate private key file name within the ConfigMap / Secret. Omit when the key is not necessary.

| `name`
| `string`
| name of the ConfigMap or Secret containing certificates

| `type`
| `string`
| type for the certificate reference: configmap or secret

|===
=== .spec.processor.resources
Description::
+
--
resources are the compute resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `limits`
| `integer-or-string`
| Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `requests`
| `integer-or-string`
| Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
=== .status
Description::
+
--
FlowCollectorStatus defines the observed state of FlowCollector
--

Type::
  `object`

Required::
  - `conditions`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `conditions`
| `array`
| conditions represent the latest available observations of an object's state

| `conditions[]`
| `object`
| Condition contains details for one aspect of the current state of this API Resource. --- This struct is intended for direct use as an array at the field path .status.conditions.  For example, type FooStatus struct{     // Represents the observations of a foo's current state.     // Known .status.conditions.type are: "Available", "Progressing", and "Degraded"     // +patchMergeKey=type     // +patchStrategy=merge     // +listType=map     // +listMapKey=type     Conditions []metav1.Condition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,1,rep,name=conditions"` 
     // other fields }

| `namespace`
| `string`
| namespace where console plugin and flowlogs-pipeline have been deployed.

|===
=== .status.conditions
Description::
+
--
conditions represent the latest available observations of an object's state
--

Type::
  `array`




=== .status.conditions[]
Description::
+
--
Condition contains details for one aspect of the current state of this API Resource. --- This struct is intended for direct use as an array at the field path .status.conditions.  For example, type FooStatus struct{     // Represents the observations of a foo's current state.     // Known .status.conditions.type are: "Available", "Progressing", and "Degraded"     // +patchMergeKey=type     // +patchStrategy=merge     // +listType=map     // +listMapKey=type     Conditions []metav1.Condition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,1,rep,name=conditions"` 
     // other fields }
--

Type::
  `object`

Required::
  - `lastTransitionTime`
  - `message`
  - `reason`
  - `status`
  - `type`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `lastTransitionTime`
| `string`
| lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.

| `message`
| `string`
| message is a human readable message indicating details about the transition. This may be an empty string.

| `observedGeneration`
| `integer`
| observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance.

| `reason`
| `string`
| reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty.

| `status`
| `string`
| status of the condition, one of True, False, Unknown.

| `type`
| `string`
| type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)

|===

== API endpoints

The following API endpoints are available:

* `/apis/flows.netobserv.io/v1alpha1/flowcollectors`
- `DELETE`: delete collection of FlowCollector
- `GET`: list objects of kind FlowCollector
- `POST`: create a FlowCollector
* `/apis/flows.netobserv.io/v1alpha1/flowcollectors/{name}`
- `DELETE`: delete a FlowCollector
- `GET`: read the specified FlowCollector
- `PATCH`: partially update the specified FlowCollector
- `PUT`: replace the specified FlowCollector
* `/apis/flows.netobserv.io/v1alpha1/flowcollectors/{name}/status`
- `GET`: read status of the specified FlowCollector
- `PATCH`: partially update status of the specified FlowCollector
- `PUT`: replace status of the specified FlowCollector


=== /apis/flows.netobserv.io/v1alpha1/flowcollectors


.Global query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `pretty`
| `string`
| If &#x27;true&#x27;, then the output is pretty printed.
|===

HTTP method::
  `DELETE`

Description::
  delete collection of FlowCollector


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `allowWatchBookmarks`
| `boolean`
| allowWatchBookmarks requests watch events with type &quot;BOOKMARK&quot;. Servers that do not implement bookmarks may ignore this flag and bookmarks are sent at the server&#x27;s discretion. Clients should not assume bookmarks are returned at any specific interval, nor may they assume the server will send any BOOKMARK event during a session. If this is not a watch, this field is ignored.
| `continue`
| `string`
| The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the &quot;next key&quot;.

This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.
| `fieldSelector`
| `string`
| A selector to restrict the list of returned objects by their fields. Defaults to everything.
| `labelSelector`
| `string`
| A selector to restrict the list of returned objects by their labels. Defaults to everything.
| `limit`
| `integer`
| limit is a maximum number of responses to return for a list call. If more items exist, the server will set the &#x60;continue&#x60; field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.

The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.
| `resourceVersion`
| `string`
| resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
| `resourceVersionMatch`
| `string`
| resourceVersionMatch determines how resourceVersion is applied to list calls. It is highly recommended that resourceVersionMatch be set for list calls where resourceVersion is set See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
| `timeoutSeconds`
| `integer`
| Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.
| `watch`
| `boolean`
| Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.
|===


.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.Status[`Status`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `GET`

Description::
  list objects of kind FlowCollector


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `allowWatchBookmarks`
| `boolean`
| allowWatchBookmarks requests watch events with type &quot;BOOKMARK&quot;. Servers that do not implement bookmarks may ignore this flag and bookmarks are sent at the server&#x27;s discretion. Clients should not assume bookmarks are returned at any specific interval, nor may they assume the server will send any BOOKMARK event during a session. If this is not a watch, this field is ignored.
| `continue`
| `string`
| The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the &quot;next key&quot;.

This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.
| `fieldSelector`
| `string`
| A selector to restrict the list of returned objects by their fields. Defaults to everything.
| `labelSelector`
| `string`
| A selector to restrict the list of returned objects by their labels. Defaults to everything.
| `limit`
| `integer`
| limit is a maximum number of responses to return for a list call. If more items exist, the server will set the &#x60;continue&#x60; field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.

The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.
| `resourceVersion`
| `string`
| resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
| `resourceVersionMatch`
| `string`
| resourceVersionMatch determines how resourceVersion is applied to list calls. It is highly recommended that resourceVersionMatch be set for list calls where resourceVersion is set See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
| `timeoutSeconds`
| `integer`
| Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.
| `watch`
| `boolean`
| Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.
|===


.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../objects/index.adoc#io.netobserv.flows.v1alpha1.FlowCollectorList[`FlowCollectorList`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `POST`

Description::
  create a FlowCollector


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `fieldManager`
| `string`
| fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.
| `fieldValidation`
| `string`
| fieldValidation instructs the server on how to handle objects in the request (POST/PUT/PATCH) containing unknown or duplicate fields, provided that the &#x60;ServerSideFieldValidation&#x60; feature gate is also enabled. Valid values are: - Ignore: This will ignore any unknown fields that are silently dropped from the object, and will ignore all but the last duplicate field that the decoder encounters. This is the default behavior prior to v1.23 and is the default behavior when the &#x60;ServerSideFieldValidation&#x60; feature gate is disabled. - Warn: This will send a warning via the standard warning response header for each unknown field that is dropped from the object, and for each duplicate field that is encountered. The request will still succeed if there are no other errors, and will only persist the last of any duplicate fields. This is the default when the &#x60;ServerSideFieldValidation&#x60; feature gate is enabled. - Strict: This will fail the request with a BadRequest error if any unknown fields would be dropped from the object, or if any duplicate fields are present. The error returned from the server will contain all unknown and duplicate fields encountered.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 201 - Created
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 202 - Accepted
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 401 - Unauthorized
| Empty
|===


=== /apis/flows.netobserv.io/v1alpha1/flowcollectors/{name}

.Global path parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `name`
| `string`
| name of the FlowCollector
|===

.Global query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `pretty`
| `string`
| If &#x27;true&#x27;, then the output is pretty printed.
|===

HTTP method::
  `DELETE`

Description::
  delete a FlowCollector


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `gracePeriodSeconds`
| `integer`
| The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.
| `orphanDependents`
| `boolean`
| Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the &quot;orphan&quot; finalizer will be added to/removed from the object&#x27;s finalizers list. Either this field or PropagationPolicy may be set, but not both.
| `propagationPolicy`
| `string`
| Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: &#x27;Orphan&#x27; - orphan the dependents; &#x27;Background&#x27; - allow the garbage collector to delete the dependents in the background; &#x27;Foreground&#x27; - a cascading policy that deletes all dependents in the foreground.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.DeleteOptions[`DeleteOptions`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.Status[`Status`] schema
| 202 - Accepted
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.Status[`Status`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `GET`

Description::
  read the specified FlowCollector


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `resourceVersion`
| `string`
| resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
|===


.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `PATCH`

Description::
  partially update the specified FlowCollector


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `fieldManager`
| `string`
| fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.
| `fieldValidation`
| `string`
| fieldValidation instructs the server on how to handle objects in the request (POST/PUT/PATCH) containing unknown or duplicate fields, provided that the &#x60;ServerSideFieldValidation&#x60; feature gate is also enabled. Valid values are: - Ignore: This will ignore any unknown fields that are silently dropped from the object, and will ignore all but the last duplicate field that the decoder encounters. This is the default behavior prior to v1.23 and is the default behavior when the &#x60;ServerSideFieldValidation&#x60; feature gate is disabled. - Warn: This will send a warning via the standard warning response header for each unknown field that is dropped from the object, and for each duplicate field that is encountered. The request will still succeed if there are no other errors, and will only persist the last of any duplicate fields. This is the default when the &#x60;ServerSideFieldValidation&#x60; feature gate is enabled. - Strict: This will fail the request with a BadRequest error if any unknown fields would be dropped from the object, or if any duplicate fields are present. The error returned from the server will contain all unknown and duplicate fields encountered.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.Patch[`Patch`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `PUT`

Description::
  replace the specified FlowCollector


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `fieldManager`
| `string`
| fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.
| `fieldValidation`
| `string`
| fieldValidation instructs the server on how to handle objects in the request (POST/PUT/PATCH) containing unknown or duplicate fields, provided that the &#x60;ServerSideFieldValidation&#x60; feature gate is also enabled. Valid values are: - Ignore: This will ignore any unknown fields that are silently dropped from the object, and will ignore all but the last duplicate field that the decoder encounters. This is the default behavior prior to v1.23 and is the default behavior when the &#x60;ServerSideFieldValidation&#x60; feature gate is disabled. - Warn: This will send a warning via the standard warning response header for each unknown field that is dropped from the object, and for each duplicate field that is encountered. The request will still succeed if there are no other errors, and will only persist the last of any duplicate fields. This is the default when the &#x60;ServerSideFieldValidation&#x60; feature gate is enabled. - Strict: This will fail the request with a BadRequest error if any unknown fields would be dropped from the object, or if any duplicate fields are present. The error returned from the server will contain all unknown and duplicate fields encountered.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 201 - Created
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 401 - Unauthorized
| Empty
|===


=== /apis/flows.netobserv.io/v1alpha1/flowcollectors/{name}/status

.Global path parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `name`
| `string`
| name of the FlowCollector
|===

.Global query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `pretty`
| `string`
| If &#x27;true&#x27;, then the output is pretty printed.
|===

HTTP method::
  `GET`

Description::
  read status of the specified FlowCollector


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `resourceVersion`
| `string`
| resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
|===


.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `PATCH`

Description::
  partially update status of the specified FlowCollector


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `fieldManager`
| `string`
| fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.
| `fieldValidation`
| `string`
| fieldValidation instructs the server on how to handle objects in the request (POST/PUT/PATCH) containing unknown or duplicate fields, provided that the &#x60;ServerSideFieldValidation&#x60; feature gate is also enabled. Valid values are: - Ignore: This will ignore any unknown fields that are silently dropped from the object, and will ignore all but the last duplicate field that the decoder encounters. This is the default behavior prior to v1.23 and is the default behavior when the &#x60;ServerSideFieldValidation&#x60; feature gate is disabled. - Warn: This will send a warning via the standard warning response header for each unknown field that is dropped from the object, and for each duplicate field that is encountered. The request will still succeed if there are no other errors, and will only persist the last of any duplicate fields. This is the default when the &#x60;ServerSideFieldValidation&#x60; feature gate is enabled. - Strict: This will fail the request with a BadRequest error if any unknown fields would be dropped from the object, or if any duplicate fields are present. The error returned from the server will contain all unknown and duplicate fields encountered.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.Patch[`Patch`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `PUT`

Description::
  replace status of the specified FlowCollector


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `fieldManager`
| `string`
| fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.
| `fieldValidation`
| `string`
| fieldValidation instructs the server on how to handle objects in the request (POST/PUT/PATCH) containing unknown or duplicate fields, provided that the &#x60;ServerSideFieldValidation&#x60; feature gate is also enabled. Valid values are: - Ignore: This will ignore any unknown fields that are silently dropped from the object, and will ignore all but the last duplicate field that the decoder encounters. This is the default behavior prior to v1.23 and is the default behavior when the &#x60;ServerSideFieldValidation&#x60; feature gate is disabled. - Warn: This will send a warning via the standard warning response header for each unknown field that is dropped from the object, and for each duplicate field that is encountered. The request will still succeed if there are no other errors, and will only persist the last of any duplicate fields. This is the default when the &#x60;ServerSideFieldValidation&#x60; feature gate is enabled. - Strict: This will fail the request with a BadRequest error if any unknown fields would be dropped from the object, or if any duplicate fields are present. The error returned from the server will contain all unknown and duplicate fields encountered.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 201 - Created
| xref:../flows_netobserv_io/flowcollector-flows-netobserv-io-v1alpha1.adoc#flowcollector-flows-netobserv-io-v1alpha1[`FlowCollector`] schema
| 401 - Unauthorized
| Empty
|===


